{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Python/billing_data_dummied.csv', dtype={'Parent_ABA': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.pop('Total Volume')                         # Remove the volume column\n",
    "df.insert(len(df.columns), 'Total Volume', data)     # Add it back in as the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Morgan Stanley; for testing 026014630\n",
    "df_MS =df[df['Parent_ABA'] == '026014630']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1982077826.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_MS.drop(columns=['Parent_ABA', 'CYCLE_D'], inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_MS.drop(columns=['Parent_ABA', 'CYCLE_D'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_MS = scaler.fit_transform(df_MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_MS[:, -1]        # Remove the volume column; set our target variable\n",
    "x = df_MS[:, :-1]       # Filter out unnecessary columns for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Use skleans TimeSeriesSplit to split our data for training\n",
    "# Assumes the data is already sorted in ascending order by date\n",
    "tss = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "for train_index, test_index in tss.split(x):\n",
    "    \n",
    "    X_train, X_test = x[train_index, :], x[test_index, :]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(\"C:/Python/billing_X_train.csv\")\n",
    "#X_test = pd.read_csv(\"C:/Python/billing_X_test.csv\")\n",
    "\n",
    "#y_train = pd.read_csv(\"C:/Python/billing_y_train.csv\")\n",
    "#y_test = pd.read_csv(\"C:/Python/billing_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop index column of pd dataframe\n",
    "#X_train.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "#X_test.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "#y_train.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "#y_test.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.90063902e-02, 1.67286211e-07, 9.02525838e-02, ...,\n",
       "       0.00000000e+00, 2.00743453e-06, 3.91516649e-03])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM-based time series predictor for multiple features.\n",
    "\n",
    "    Args:\n",
    "        num_features (int): Number of input features.\n",
    "        n_hidden (int, optional): Number of hidden units in each LSTM layer. Default is 51.\n",
    "        num_layers (int, optional): Number of LSTM layers. Default is 2.\n",
    "\n",
    "    Attributes:\n",
    "        num_features (int): Number of input features.\n",
    "        n_hidden (int): Number of hidden units in each LSTM layer.\n",
    "        num_layers (int): Number of LSTM layers.\n",
    "        lstm_layers (nn.ModuleList): Stack of LSTM layers.\n",
    "        linear (nn.Linear): Linear layer for prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> model = LSTMPredictor(num_features=5, num_layers=3)\n",
    "        >>> input_data = torch.randn(32, 10, 5)  # Batch size of 32, sequence length of 10\n",
    "        >>> predictions = model(input_data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, n_hidden=51, num_layers=2):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM predictor.\n",
    "\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            n_hidden (int, optional): Number of hidden units in each LSTM layer. Default is 51.\n",
    "            num_layers (int, optional): Number of LSTM layers. Default is 2.\n",
    "        \"\"\"\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize a stack of LSTM layers\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTMCell(num_features if i == 0 else n_hidden, n_hidden)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Linear layer for prediction\n",
    "        self.linear = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x, future=0):\n",
    "        \"\"\"\n",
    "        Forward pass through the LSTM predictor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data of shape (batch_size, seq_len, num_features).\n",
    "            future (int, optional): Number of future time steps to predict. Default is 0.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted output of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        n_samples, seq_len, _ = x.size()\n",
    "\n",
    "        # Initialize hidden states for each layer\n",
    "        hidden_states = [\n",
    "            (torch.zeros(n_samples, self.n_hidden, dtype=torch.float32),\n",
    "            torch.zeros(n_samples, self.n_hidden, dtype=torch.float32))\n",
    "            for _ in range(self.num_layers)\n",
    "        ]\n",
    "\n",
    "        # Iterate over each time step\n",
    "        for t in range(seq_len):\n",
    "            input_t = x[:, t, :]\n",
    "            for i in range(self.num_layers):\n",
    "                hidden_states[i] = self.lstm_layers[i](input_t, hidden_states[i])\n",
    "                input_t = hidden_states[i][0]  # Pass output of previous layer as input\n",
    "\n",
    "        # Use output of last layer\n",
    "        output = self.linear(input_t)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM-based time series predictor for multiple features.\n",
    "\n",
    "    Args:\n",
    "        num_features (int): Number of input features.\n",
    "        n_hidden (int, optional): Number of hidden units in each LSTM layer. Default is 51.\n",
    "        num_layers (int, optional): Number of LSTM layers. Default is 2.\n",
    "\n",
    "    Attributes:\n",
    "        num_features (int): Number of input features.\n",
    "        n_hidden (int): Number of hidden units in each LSTM layer.\n",
    "        num_layers (int): Number of LSTM layers.\n",
    "        lstm (nn.LSTM): LSTM layers.\n",
    "        linear (nn.Linear): Linear layer for prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> model = LSTMPredictor(num_features=5, num_layers=3)\n",
    "        >>> input_data = torch.randn(32, 10, 5)  # Batch size of 32, sequence length of 10\n",
    "        >>> predictions = model(input_data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, n_hidden=51, num_layers=2):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM predictor.\n",
    "\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            n_hidden (int, optional): Number of hidden units in each LSTM layer. Default is 51.\n",
    "            num_layers (int, optional): Number of LSTM layers. Default is 2.\n",
    "        \"\"\"\n",
    "\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=n_hidden, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the LSTM predictor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data of shape (batch_size, seq_len, num_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted output of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass the input through the LSTM layers\n",
    "        # The LSTM layers return the outputs and the final hidden states\n",
    "        lstm_out, _ = self.lstm(x)  \n",
    "\n",
    "        # We only need the output at the last time step\n",
    "        last_time_step = lstm_out[:, -1, :]  \n",
    "\n",
    "        # Pass it through the output layer\n",
    "        out = self.linear(last_time_step)  \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensors = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensors = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensors = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensors = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(X_train_tensors[0])\n",
    "X_train_tensors[0] = X_train_tensors[0].view(-1, 1, num_features)\n",
    "X_train_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:18:34,492\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-30 18:18:49</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:14.76        </td></tr>\n",
       "<tr><td>Memory:      </td><td>26.0/63.8 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T1000)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 10<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_12828_00000</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00000_0_lr=0.0005,n_hidden=10,num_features=94,num_layers=2_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00001</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00001_1_lr=0.0004,n_hidden=50,num_features=94,num_layers=2_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00002</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00002_2_lr=0.0001,n_hidden=10,num_features=94,num_layers=1_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00003</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00003_3_lr=0.0002,n_hidden=10,num_features=94,num_layers=1_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00004</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00004_4_lr=0.0002,n_hidden=50,num_features=94,num_layers=2_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00005</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00005_5_lr=0.0010,n_hidden=20,num_features=94,num_layers=3_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00006</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00006_6_lr=0.0063,n_hidden=10,num_features=94,num_layers=1_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00007</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00007_7_lr=0.0003,n_hidden=50,num_features=94,num_layers=1_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00008</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00008_8_lr=0.0003,n_hidden=50,num_features=94,num_layers=3_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "<tr><td>train_model_12828_00009</td><td style=\"text-align: right;\">           1</td><td>C:/Users/G1RXK02/AppData/Local/Temp/ray/session_2024-06-30_16-15-19_906653_23204/artifacts/2024-06-30_18-18-34/train_model_2024-06-30_18-18-34/driver_artifacts/train_model_12828_00009_9_lr=0.0862,n_hidden=50,num_features=94,num_layers=1_2024-06-30_18-18-34/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  n_hidden</th><th style=\"text-align: right;\">  num_features</th><th style=\"text-align: right;\">  num_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_12828_00000</td><td>ERROR   </td><td>127.0.0.1:22644</td><td style=\"text-align: right;\">0.000497013</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           2</td></tr>\n",
       "<tr><td>train_model_12828_00001</td><td>ERROR   </td><td>127.0.0.1:15276</td><td style=\"text-align: right;\">0.000363518</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           2</td></tr>\n",
       "<tr><td>train_model_12828_00002</td><td>ERROR   </td><td>127.0.0.1:27636</td><td style=\"text-align: right;\">0.000101754</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>train_model_12828_00003</td><td>ERROR   </td><td>127.0.0.1:19748</td><td style=\"text-align: right;\">0.000181902</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>train_model_12828_00004</td><td>ERROR   </td><td>127.0.0.1:14364</td><td style=\"text-align: right;\">0.000188561</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           2</td></tr>\n",
       "<tr><td>train_model_12828_00005</td><td>ERROR   </td><td>127.0.0.1:4556 </td><td style=\"text-align: right;\">0.000963516</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>train_model_12828_00006</td><td>ERROR   </td><td>127.0.0.1:8912 </td><td style=\"text-align: right;\">0.00631418 </td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>train_model_12828_00007</td><td>ERROR   </td><td>127.0.0.1:28992</td><td style=\"text-align: right;\">0.000294378</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>train_model_12828_00008</td><td>ERROR   </td><td>127.0.0.1:25064</td><td style=\"text-align: right;\">0.0003183  </td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>train_model_12828_00009</td><td>ERROR   </td><td>127.0.0.1:29976</td><td style=\"text-align: right;\">0.0862119  </td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">            94</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:18:49,068\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=8912, ip=127.0.0.1, actor_id=b583a75664837ca1643269c601000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_12828_00000</td></tr>\n",
       "<tr><td>train_model_12828_00001</td></tr>\n",
       "<tr><td>train_model_12828_00002</td></tr>\n",
       "<tr><td>train_model_12828_00003</td></tr>\n",
       "<tr><td>train_model_12828_00004</td></tr>\n",
       "<tr><td>train_model_12828_00005</td></tr>\n",
       "<tr><td>train_model_12828_00006</td></tr>\n",
       "<tr><td>train_model_12828_00007</td></tr>\n",
       "<tr><td>train_model_12828_00008</td></tr>\n",
       "<tr><td>train_model_12828_00009</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:18:49,081\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4556, ip=127.0.0.1, actor_id=a27fa029ee581af7decf444b01000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,098\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25064, ip=127.0.0.1, actor_id=68925fd55d670d71f760142401000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,098\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=14364, ip=127.0.0.1, actor_id=9aad8e3cd1b900d7bf68469a01000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,115\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00009\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=29976, ip=127.0.0.1, actor_id=e50f8c09277be4a1a11ac99401000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,137\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=19748, ip=127.0.0.1, actor_id=36b933cc230c83ca2b75bc8201000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,149\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=15276, ip=127.0.0.1, actor_id=6d06cb912de5ddd664be9ca001000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,149\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27636, ip=127.0.0.1, actor_id=0b9ec3dc6f741814069d656701000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,169\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=22644, ip=127.0.0.1, actor_id=3f5a308364fda0d1e8ba8bba01000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,183\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12828_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28992, ip=127.0.0.1, actor_id=63c8b1e8413c4fd78c07960b01000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\G1RXK02\\AppData\\Local\\Temp\\ipykernel_23204\\1221051122.py\", line 27, in train_model\n",
      "RuntimeError: shape '[-1, 12, 94]' is invalid for input of size 94\n",
      "2024-06-30 18:18:49,278\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/G1RXK02/ray_results/train_model_2024-06-30_18-18-34' in 0.0708s.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_model_12828_00000, train_model_12828_00001, train_model_12828_00002, train_model_12828_00003, train_model_12828_00004, train_model_12828_00005, train_model_12828_00006, train_model_12828_00007, train_model_12828_00008, train_model_12828_00009])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 48\u001b[0m\n\u001b[0;32m     40\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;28mlen\u001b[39m(X_train_tensors[\u001b[38;5;241m0\u001b[39m])]),\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_hidden\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m]),\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]),\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m),\n\u001b[0;32m     45\u001b[0m }\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Run the hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m     51\u001b[0m best_config \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_best_config(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ray\\tune\\tune.py:1035\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_model_12828_00000, train_model_12828_00001, train_model_12828_00002, train_model_12828_00003, train_model_12828_00004, train_model_12828_00005, train_model_12828_00006, train_model_12828_00007, train_model_12828_00008, train_model_12828_00009])"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "def train_model(config):\n",
    "    \"\"\"\n",
    "    Train an LSTM model with the given hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Dictionary containing the hyperparameters for the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the loss of the model.\n",
    "    \"\"\"\n",
    "    # Define your model with the given hyperparameters\n",
    "    model = LSTMPredictor(num_features=config[\"num_features\"], n_hidden=config[\"n_hidden\"], num_layers=config[\"num_layers\"])\n",
    "\n",
    "    # Define your loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # Train your model\n",
    "    for epoch in range(100):  # You can adjust the number of epochs\n",
    "        for i in range(len(X_train_tensors)):\n",
    "            # Forward pass\n",
    "            seq_len = 12  # replace with actual sequence length\n",
    "            num_features = len(X_train_tensors[i]) // seq_len\n",
    "            num_features = config[\"num_features\"]\n",
    "            X_train_tensors[i] = X_train_tensors[i].view(-1, seq_len, num_features)      # Ensure it's a 3D tensor\n",
    "            outputs = model(X_train_tensors[i])\n",
    "            loss = criterion(outputs, y_train_tensors[i])\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Report the loss to Tune, which is minimized\n",
    "        tune.report(loss=loss.item())\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "config = {\n",
    "    \"num_features\": tune.choice([len(X_train_tensors[0])]),\n",
    "    \"n_hidden\": tune.choice([10, 20, 30, 40, 50]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "\n",
    "# Run the hyperparameter tuning\n",
    "analysis = tune.run(train_model, config=config, num_samples=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_config = analysis.get_best_config(metric=\"loss\", mode=\"min\")\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# Wrap your model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    module=LSTMPredictor,\n",
    "    max_epochs=100,  # Set an appropriate number of epochs\n",
    "    lr=0.001,  # Initial learning rate (you can tune this too)\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion = nn.MSELoss(),\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    ")\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_dist = {\n",
    "    'module__n_hidden': [32, 64, 128],\n",
    "    'module__num_features': [len(X_train[0])], \n",
    "    'module__num_layers': [2, 3, 4],  \n",
    "    'lr': [0.001, 0.01, 0.1],  \n",
    "    # Add other hyperparameters you want to tune\n",
    "}\n",
    "\n",
    "# Perform random grid search\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,                          # Number of random samples\n",
    "    #cv = KFold(n_splits=5, \n",
    "     #          shuffle=True, \n",
    "      #         random_state=42),        # Cross-validation folds\n",
    "    scoring='neg_mean_squared_error',   # Choose an appropriate metric\n",
    "    verbose=1,\n",
    "    n_jobs=-1,                          # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Fit the random search to your data\n",
    "random_search.fit(X_train, y = y_train)\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Evaluate the best model on your validation set\n",
    "val_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time step's output\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "model = LSTMModel(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test.unsqueeze(1))\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "predicted_volume = scaler.inverse_transform(test_outputs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the following arrays (replace with your actual data)\n",
    "customer_ids = np.array([1, 2, 3, ...])  # Replace with your customer IDs\n",
    "product_ids = np.array([101, 102, 103, ...])  # Replace with your product IDs\n",
    "\n",
    "# Create a DataFrame for predicted volume\n",
    "predicted_df = pd.DataFrame({\n",
    "    'customer_id': customer_ids,\n",
    "    'product_id': product_ids,\n",
    "    'predicted_volume': predicted_volume.flatten()  # Flatten the 2D array\n",
    "})\n",
    "\n",
    "# Now you can join this DataFrame with your original data\n",
    "# Assuming your original DataFrame is called 'original_df'\n",
    "merged_df = original_df.merge(predicted_df, on=['customer_id', 'product_id'], how='left')\n",
    "\n",
    "# 'merged_df' now contains the predicted volume alongside customer and product information\n",
    "print(merged_df.head())  # Check the merged DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model for time series forecasting.\n",
    "\n",
    "    Attributes:\n",
    "        num_classes (int): The number of output classes.\n",
    "        num_layers (int): The number of recurrent layers.\n",
    "        input_size (int): The number of expected features in the input x.\n",
    "        hidden_size (int): The number of features in the hidden state h.\n",
    "        seq_length (int): The sequence length of the time series data.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): The number of output classes.\n",
    "            num_layers (int): The number of recurrent layers.\n",
    "            input_size (int): The number of expected features in the input x.\n",
    "            hidden_size (int): The number of features in the hidden state h.\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the LSTM layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input to the LSTM layer.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output from the LSTM layer.\n",
    "        \"\"\"\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"\"\"\n",
    "    Train the LSTM model and report the loss to Tune.\n",
    "\n",
    "    Args:\n",
    "        config (dict): A dictionary containing the hyperparameters for training.\n",
    "    \"\"\"\n",
    "    # Define model\n",
    "    model = LSTM(input_size=1, hidden_size=int(config[\"hidden_size\"]), output_size=1, num_layers=int(config[\"num_layers\"]))\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # Train model\n",
    "    epochs = 150\n",
    "    for i in range(epochs):\n",
    "        for seq, labels in zip(x_train_tensors, y_train_tensors):\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Report the loss to Tune\n",
    "        with tune.checkpoint_dir(step=i) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=single_loss.item())\n",
    "\n",
    "# Define the search space\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"hidden_size\": tune.choice([50, 100, 200]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3])\n",
    "}\n",
    "\n",
    "# Define the scheduler and reporter\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=150,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"loss\", \"training_iteration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the possible combinations of Parent ABA and Produce Code\n",
    "combinations = df[['Parent_ABA', 'Service Code']].drop_duplicates()\n",
    "\n",
    "# Define a dictionary to store the best model for each combination\n",
    "best_models = {}\n",
    "\n",
    "for _, row in combinations.iterrows():\n",
    "    parent_aba = row['Parent_ABA']\n",
    "    service_code = row['Service Code']\n",
    "\n",
    "    # Filter data for this combination\n",
    "    data = df[(df['Parent_ABA'] == parent_aba) & (df['Service Code'] == service_code]['Total Volume']\n",
    "              \n",
    "    # Preprocess data and split into training and testing sets\n",
    "    # ... (insert your preprocessing and train-test split code here) ...\n",
    "\n",
    "    # Convert your training and testing sets into PyTorch tensors\n",
    "    # ... (insert your code to convert to PyTorch tensors here) ...\n",
    "\n",
    "    # Run the hyperparameter search\n",
    "    analysis = tune.run(train_model, config=config, scheduler=scheduler, progress_reporter=reporter)\n",
    "\n",
    "    # Get the best model and store it in the dictionary\n",
    "    best_trial = analysis.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "\n",
    "    best_trained_model = LSTM(input_size=1, hidden_size=int(best_trial.config[\"hidden_size\"]), output_size=1, num_layers=int(best_trial.config[\"num_layers\"]))\n",
    "    best_trained_model.load_state_dict(torch.load(os.path.join(best_trial.checkpoint.value, \"checkpoint\"))[0])\n",
    "\n",
    "    best_models[(customer_id, product_id)] = best_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_model(models, x_test_tensors_dict, y_test_tensors_dict):\n",
    "    \"\"\"\n",
    "    Evaluate the LSTM models on the test data.\n",
    "\n",
    "    Args:\n",
    "        models (dict): A dictionary containing the trained LSTM models.\n",
    "        x_test_tensors_dict (dict): A dictionary containing the input sequences for the test data.\n",
    "        y_test_tensors_dict (dict): A dictionary containing the target values for the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    for (customer_id, product_id), model in models.items():\n",
    "        print(f\"Evaluating model for customer_id {customer_id} and product_id {product_id}:\")\n",
    "\n",
    "        # Get the test data for this combination\n",
    "        x_test_tensors = x_test_tensors_dict[(customer_id, product_id)]\n",
    "        y_test_tensors = y_test_tensors_dict[(customer_id, product_id)]\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for seq in x_test_tensors:\n",
    "                model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                                torch.zeros(1, 1, model.hidden_layer_size))\n",
    "                predictions.append(model(seq).item())\n",
    "\n",
    "        # Compare predictions to actual values\n",
    "        for i in range(len(y_test_tensors)):\n",
    "            print(f'Predicted: {predictions[i]}, Actual: {y_test_tensors[i].item()}')\n",
    "\n",
    "        # Calculate and print the Mean Squared Error and Mean Absolute Error\n",
    "        mse = mean_squared_error(y_test_tensors, predictions)\n",
    "        mae = mean_absolute_error(y_test_tensors, predictions)\n",
    "        print(f'Mean Squared Error: {mse}, Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_models, x_test_tensors_dict, y_test_tensors_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your XGBoost model\n",
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters and their potential distributions\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 6),\n",
    "    'subsample': uniform(0.8, 0.2),\n",
    "    'colsample_bytree': uniform(0.8, 0.2),\n",
    "    'reg_lambda': uniform(0.1, 10.0),\n",
    "    'reg_alpha': uniform(0.1, 10.0)\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "randomized_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=50, cv=5)\n",
    "randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = randomized_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyper-parameters further based on best parameters results from the random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters and their potential values\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0.1, 1.0, 10.0],\n",
    "    'reg_alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
